{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62225812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14cd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802fcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import timm\n",
    "\n",
    "# --- TDA Imports ---\n",
    "try:\n",
    "    import gudhi as gd\n",
    "    TDA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TDA_AVAILABLE = False\n",
    "    print(\"âš  'gudhi' library not found. TDA features will be zeros. Run: pip install gudhi\")\n",
    "\n",
    "try:\n",
    "    from persim import PersistenceImager\n",
    "    PERSIM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PERSIM_AVAILABLE = False\n",
    "    print(\"âš  'persim' library not found. Persistence images will be zeros. Run: pip install persim\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "config = {\n",
    "    \"csv_path\": \"train.csv\",\n",
    "    \"img_root\": \"../dataset/india_dataset/colored_images\",\n",
    "    \"backbone\": \"efficientnet_b2\",\n",
    "    \"num_classes\": 5,\n",
    "    \"batch_size\": 8,\n",
    "    \"epochs\": 40,\n",
    "    \"lr\": 1e-4,\n",
    "    \"use_cbam\": True,\n",
    "    \"use_distill\": True,\n",
    "    \"teacher_backbone\": \"efficientnet_b5\",\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"early_stop_patience\": 5,\n",
    "    \"gradcam_out_dir\": \"B2_B5_Distill_TDA_PI\",\n",
    "    \"image_size\": 224,\n",
    "\n",
    "    # Teacher Training Config\n",
    "    \"train_teacher\": True,\n",
    "    \"teacher_epochs\": 15,\n",
    "\n",
    "    # Distillation Config\n",
    "    \"distill_alpha_start\": 0.2,\n",
    "    \"distill_alpha_end\": 0.8,\n",
    "    \"distill_temperature\": 4.0,\n",
    "\n",
    "    # Regularization\n",
    "    \"consistency_weight\": 0.1,\n",
    "    \"use_class_weights\": True,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"max_grad_norm\": 5.0,\n",
    "    \"rotation_angles\": [0, 90, 180, 270],\n",
    "\n",
    "    # TDA Config (persistence images)\n",
    "    \"use_tda\": True,\n",
    "    \"tda_img_size\": 32,\n",
    "    \"tda_mlp_dims\": [512, 128],\n",
    "\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Device Setup\n",
    "# -------------------------\n",
    "device = torch.device(config[\"device\"])\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"âœ… Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"âš  No GPU found. Using CPU.\")\n",
    "\n",
    "# -------------------------\n",
    "# Data Transforms & Dataset\n",
    "# -------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def _init_(self, csv_file, img_root, transform=None, img_exts=(\".png\", \".jpg\", \".jpeg\")):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "        # Normalize column names\n",
    "        self.data.columns = [c.strip().lower() for c in self.data.columns]\n",
    "        self.image_col = self.data.columns[0]\n",
    "        self.label_col = self.data.columns[1]\n",
    "\n",
    "        self.folder_names = sorted(\n",
    "            [f for f in os.listdir(img_root)\n",
    "             if os.path.isdir(os.path.join(img_root, f))]\n",
    "        )\n",
    "        self.numeric_to_folder = {\n",
    "            0: \"No_DR\",\n",
    "            1: \"Mild\",\n",
    "            2: \"Moderate\",\n",
    "            3: \"Severe\",\n",
    "            4: \"Proliferate_DR\"\n",
    "        }\n",
    "        self.img_exts = img_exts\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _find_image(self, folder, img_id):\n",
    "        for ext in self.img_exts:\n",
    "            p = os.path.join(self.img_root, folder, f\"{img_id}{ext}\")\n",
    "            if os.path.exists(p):\n",
    "                return p\n",
    "        p = os.path.join(self.img_root, folder, img_id)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "        raise FileNotFoundError(f\"Image for id {img_id} not found in {folder}\")\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        img_id = str(self.data.iloc[idx][self.image_col])\n",
    "        label_val = self.data.iloc[idx][self.label_col]\n",
    "\n",
    "        if isinstance(label_val, (int, float)) or str(label_val).isdigit():\n",
    "            label_val = int(label_val)\n",
    "            folder_name = self.numeric_to_folder[label_val]\n",
    "            label_idx = label_val\n",
    "        else:\n",
    "            folder_name = str(label_val)\n",
    "            label_idx = self.folder_names.index(folder_name)\n",
    "\n",
    "        img_path = self._find_image(folder_name, img_id)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx\n",
    "\n",
    "# -------------------------\n",
    "# Load Dataset & Create Train/Val/Test Split (70/15/15) - âœ… FIXED\n",
    "# -------------------------\n",
    "dataset = None\n",
    "use_imagefolder = False\n",
    "\n",
    "if os.path.exists(config[\"csv_path\"]) and os.path.isdir(config[\"img_root\"]):\n",
    "    try:\n",
    "        dataset = RetinopathyDataset(config[\"csv_path\"], config[\"img_root\"], transform=train_transform)\n",
    "        print(\"âœ… Loaded dataset from CSV + folders.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Failed to load CSV-based dataset: {e}\")\n",
    "        dataset = None\n",
    "\n",
    "if dataset is None:\n",
    "    if os.path.isdir(config[\"img_root\"]):\n",
    "        dataset = datasets.ImageFolder(root=config[\"img_root\"], transform=train_transform)\n",
    "        use_imagefolder = True\n",
    "        print(\"âœ… Loaded dataset with ImageFolder.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Neither CSV ({config['csv_path']}) nor image root ({config['img_root']}) exist.\"\n",
    "        )\n",
    "\n",
    "if use_imagefolder:\n",
    "    class_names = dataset.classes\n",
    "else:\n",
    "    class_names = [\"No_DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "print(f\"Total dataset size: {len(dataset)}\")\n",
    "\n",
    "# âœ… FIXED: PROPER TRAIN/VAL/TEST SPLIT (70/15/15)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset split: train={len(train_ds)}, val={len(val_ds)}, test={len(test_ds)}\")\n",
    "\n",
    "# âœ… FIXED: Save split indices for reproducibility\n",
    "split_indices = {\n",
    "    \"train\": list(train_ds.indices),\n",
    "    \"val\": list(val_ds.indices),\n",
    "    \"test\": list(test_ds.indices)\n",
    "}\n",
    "torch.save(split_indices, \"split_indices.pth\")\n",
    "print(\"ðŸ’¾ Split indices saved to 'split_indices.pth'\")\n",
    "\n",
    "# Create proper validation and test datasets with val_transform\n",
    "if use_imagefolder:\n",
    "    val_dataset_full = datasets.ImageFolder(root=config[\"img_root\"], transform=val_transform)\n",
    "    test_dataset_full = datasets.ImageFolder(root=config[\"img_root\"], transform=val_transform)\n",
    "else:\n",
    "    val_dataset_full = RetinopathyDataset(config[\"csv_path\"], config[\"img_root\"], transform=val_transform)\n",
    "    test_dataset_full = RetinopathyDataset(config[\"csv_path\"], config[\"img_root\"], transform=val_transform)\n",
    "\n",
    "val_ds = Subset(val_dataset_full, val_ds.indices)\n",
    "test_ds = Subset(test_dataset_full, test_ds.indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=config[\"batch_size\"],\n",
    "    shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=config[\"batch_size\"],\n",
    "    shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=config[\"batch_size\"],\n",
    "    shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"âœ… All DataLoaders created successfully!\")\n",
    "\n",
    "# -------------------------\n",
    "# Persistence Image Utilities\n",
    "# -------------------------\n",
    "if TDA_AVAILABLE and PERSIM_AVAILABLE:\n",
    "    pimgr = PersistenceImager(birth_range=(0.0, 1.0),\n",
    "                              pers_range=(0.0, 1.0),\n",
    "                              pixel_size=None)\n",
    "else:\n",
    "    pimgr = None\n",
    "\n",
    "def compute_persistence_diagram_from_image(img_arr):\n",
    "    cc = gd.CubicalComplex(\n",
    "        dimensions=img_arr.shape,\n",
    "        top_dimensional_cells=img_arr.flatten()\n",
    "    )\n",
    "    persistence = cc.persistence()\n",
    "    diag = []\n",
    "    for dim, (b, d) in persistence:\n",
    "        if dim in (0, 1) and d != np.inf and d > b:\n",
    "            diag.append([b, d])\n",
    "    if len(diag) == 0:\n",
    "        return np.empty((0, 2), dtype=np.float32)\n",
    "    return np.array(diag, dtype=np.float32)\n",
    "\n",
    "def extract_persistence_image_batch(images_tensor, tda_img_size=32):\n",
    "    B = images_tensor.size(0)\n",
    "    if not (TDA_AVAILABLE and PERSIM_AVAILABLE):\n",
    "        return torch.zeros((B, tda_img_size * tda_img_size), device=images_tensor.device)\n",
    "\n",
    "    small_imgs = torch.nn.functional.interpolate(\n",
    "        images_tensor,\n",
    "        size=(tda_img_size, tda_img_size),\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    gray_imgs = (\n",
    "        0.299 * small_imgs[:, 0, :, :] +\n",
    "        0.587 * small_imgs[:, 1, :, :] +\n",
    "        0.114 * small_imgs[:, 2, :, :]\n",
    "    )\n",
    "    gray_imgs_np = gray_imgs.cpu().detach().numpy()\n",
    "\n",
    "    diagrams = []\n",
    "    for i in range(B):\n",
    "        img_arr = gray_imgs_np[i]\n",
    "        diag = compute_persistence_diagram_from_image(img_arr)\n",
    "        diagrams.append(diag)\n",
    "\n",
    "    global pimgr\n",
    "    if pimgr is not None and not getattr(pimgr, \"fitted_\", False):\n",
    "        non_empty_diags = [d for d in diagrams if d.shape[0] > 0]\n",
    "        if len(non_empty_diags) > 0:\n",
    "            pimgr.fit(non_empty_diags, skew=True)\n",
    "\n",
    "    batch_imgs = []\n",
    "    for dgm in diagrams:\n",
    "        if dgm.shape[0] == 0:\n",
    "            pim = np.zeros((tda_img_size, tda_img_size), dtype=np.float32)\n",
    "        else:\n",
    "            pim = pimgr.transform(dgm, skew=True)\n",
    "            pim = cv2.resize(pim.astype(np.float32), (tda_img_size, tda_img_size),\n",
    "                             interpolation=cv2.INTER_LINEAR)\n",
    "        batch_imgs.append(pim.flatten())\n",
    "\n",
    "    batch_tensor = torch.tensor(batch_imgs, dtype=torch.float32, device=images_tensor.device)\n",
    "    min_vals = batch_tensor.min(dim=1, keepdim=True)[0]\n",
    "    max_vals = batch_tensor.max(dim=1, keepdim=True)[0]\n",
    "    batch_tensor = (batch_tensor - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "    return batch_tensor\n",
    "\n",
    "# -------------------------\n",
    "# CBAM & Student Model\n",
    "# -------------------------\n",
    "class CBAMBlock(nn.Module):\n",
    "    def _init_(self, channels, reduction=16, kernel_size=7):\n",
    "        super()._init_()\n",
    "        self.channel_gate = nn.Sequential(\n",
    "            nn.Linear(channels, max(1, channels // reduction), bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(1, channels // reduction), channels, bias=False)\n",
    "        )\n",
    "        self.spatial_gate = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=kernel_size,\n",
    "                      padding=(kernel_size - 1) // 2, bias=False),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        # Channel attention\n",
    "        avg_pool = torch.mean(x, dim=(2, 3))\n",
    "        max_pool, _ = torch.max(x.view(b, c, -1), dim=2)\n",
    "        c_out = torch.sigmoid(\n",
    "            self.channel_gate(avg_pool) + self.channel_gate(max_pool)\n",
    "        ).view(b, c, 1, 1)\n",
    "        x = x * c_out\n",
    "\n",
    "        # Spatial attention\n",
    "        avg_s = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_s, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        s_out = torch.sigmoid(\n",
    "            self.spatial_gate(torch.cat([avg_s, max_s], dim=1))\n",
    "        )\n",
    "        return x * s_out\n",
    "\n",
    "class EfficientNetWithCBAM_PI(nn.Module):\n",
    "    def _init_(self, backbone_name='efficientnet_b2',\n",
    "                 num_classes=5, use_cbam=True,\n",
    "                 pretrained=True, use_tda=False,\n",
    "                 tda_img_size=32, tda_mlp_dims=[512, 128]):\n",
    "        super()._init_()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.feature_extractor = timm.create_model(\n",
    "                backbone_name,\n",
    "                pretrained=pretrained,\n",
    "                features_only=True\n",
    "            )\n",
    "\n",
    "        out_channels = self.feature_extractor.feature_info[-1]['num_chs']\n",
    "        self.use_cbam = use_cbam\n",
    "        self.cbam = CBAMBlock(out_channels) if use_cbam else None\n",
    "\n",
    "        self.use_tda = use_tda\n",
    "        self.tda_img_size = tda_img_size\n",
    "        self.tda_vec_dim = tda_img_size * tda_img_size if use_tda else 0\n",
    "\n",
    "        if use_tda:\n",
    "            mlp_layers = []\n",
    "            in_dim = self.tda_vec_dim\n",
    "            for dim in tda_mlp_dims:\n",
    "                mlp_layers.append(nn.Linear(in_dim, dim))\n",
    "                mlp_layers.append(nn.ReLU(inplace=True))\n",
    "                in_dim = dim\n",
    "            self.tda_mlp = nn.Sequential(*mlp_layers)\n",
    "            fusion_in_dim = out_channels + tda_mlp_dims[-1]\n",
    "        else:\n",
    "            self.tda_mlp = None\n",
    "            fusion_in_dim = out_channels\n",
    "\n",
    "        self.classifier = nn.Linear(fusion_in_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.feature_extractor(x)\n",
    "        if isinstance(feats, (list, tuple)):\n",
    "            feats = feats[-1]\n",
    "\n",
    "        if self.cbam:\n",
    "            feats = self.cbam(feats)\n",
    "\n",
    "        pooled = nn.functional.adaptive_avg_pool2d(feats, (1, 1)).flatten(1)\n",
    "\n",
    "        if self.use_tda:\n",
    "            tda_feats = extract_persistence_image_batch(\n",
    "                x, tda_img_size=self.tda_img_size\n",
    "            )\n",
    "            tda_feats = self.tda_mlp(tda_feats)\n",
    "            combined = torch.cat((pooled, tda_feats), dim=1)\n",
    "            logits = self.classifier(combined)\n",
    "        else:\n",
    "            logits = self.classifier(pooled)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# -------------------------\n",
    "# Loss & Trainer\n",
    "# -------------------------\n",
    "class DistillationLoss(nn.Module):\n",
    "    def _init_(self, base_loss, teacher_model=None,\n",
    "                 alpha_start=0.5, alpha_end=0.5, temperature=4.0):\n",
    "        super()._init_()\n",
    "        self.base_loss = base_loss\n",
    "        self.teacher = teacher_model\n",
    "        self.alpha_start = alpha_start\n",
    "        self.alpha_end = alpha_end\n",
    "        self.T = temperature\n",
    "        self.current_epoch = 0\n",
    "        self.max_epochs = 1\n",
    "\n",
    "        if self.teacher is not None:\n",
    "            self.teacher.eval()\n",
    "            for p in self.teacher.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def set_epoch(self, epoch, max_epochs):\n",
    "        self.current_epoch = epoch\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "    def get_alpha(self):\n",
    "        if self.max_epochs <= 1:\n",
    "            return self.alpha_end\n",
    "        frac = min(1.0, max(0.0, self.current_epoch / float(self.max_epochs - 1)))\n",
    "        return self.alpha_start + frac * (self.alpha_end - self.alpha_start)\n",
    "\n",
    "    def forward(self, student_logits, inputs, labels):\n",
    "        hard = self.base_loss(student_logits, labels)\n",
    "        if self.teacher is None:\n",
    "            return hard\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.teacher(inputs)\n",
    "\n",
    "        s_logp = nn.functional.log_softmax(student_logits / self.T, dim=1)\n",
    "        t_prob = nn.functional.softmax(teacher_logits / self.T, dim=1)\n",
    "\n",
    "        soft = nn.KLDivLoss(reduction='batchmean')(s_logp, t_prob) * (self.T * self.T)\n",
    "        alpha = self.get_alpha()\n",
    "        return alpha * soft + (1.0 - alpha) * hard\n",
    "\n",
    "class Trainer:\n",
    "    def _init_(self, model, criterion, optimizer, scheduler, device, config):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "\n",
    "    def train_epoch(self, loader, epoch_idx=0, total_epochs=1):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(imgs)\n",
    "\n",
    "            if isinstance(self.criterion, DistillationLoss):\n",
    "                if hasattr(self.criterion, \"set_epoch\"):\n",
    "                    self.criterion.set_epoch(epoch_idx, total_epochs)\n",
    "                loss = self.criterion(outputs, imgs, labels)\n",
    "            else:\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "            # Consistency regularization (rotation)\n",
    "            if self.config.get(\"consistency_weight\", 0.0) > 0.0:\n",
    "                angle = random.choice(self.config[\"rotation_angles\"])\n",
    "                if angle % 360 != 0:\n",
    "                    rotated_imgs = torch.stack(\n",
    "                        [transforms.functional.rotate(img.cpu(), angle) for img in imgs]\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        out_orig = nn.functional.log_softmax(outputs, dim=1)\n",
    "\n",
    "                    out_rot = self.model(rotated_imgs)\n",
    "                    kl_loss = nn.functional.kl_div(\n",
    "                        out_orig,\n",
    "                        nn.functional.softmax(out_rot.detach(), dim=1),\n",
    "                        reduction='batchmean'\n",
    "                    )\n",
    "                    loss += self.config[\"consistency_weight\"] * kl_loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if self.config.get(\"max_grad_norm\", None):\n",
    "                nn.utils.clip_grad_norm_(\n",
    "                    self.model.parameters(), self.config[\"max_grad_norm\"]\n",
    "                )\n",
    "\n",
    "            self.optimizer.step()\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            n += imgs.size(0)\n",
    "\n",
    "        return running_loss / max(1, n)\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        preds, trues = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                outputs = self.model(imgs)\n",
    "                preds.extend(outputs.argmax(1).cpu().numpy().tolist())\n",
    "                trues.extend(labels.numpy().tolist())\n",
    "\n",
    "        return preds, trues\n",
    "\n",
    "# -------------------------\n",
    "# EXECUTION FLOW\n",
    "# -------------------------\n",
    "\n",
    "# 1. Setup Class Weights & Base Loss (using train set only)\n",
    "class_weights = None\n",
    "if config[\"use_class_weights\"]:\n",
    "    label_counts = np.zeros(config[\"num_classes\"], dtype=np.int64)\n",
    "    for i in range(len(train_ds)):\n",
    "        _, lbl = train_ds[i]\n",
    "        label_counts[lbl] += 1\n",
    "\n",
    "    freq = label_counts / float(label_counts.sum())\n",
    "    weights = 1.0 / (freq + 1e-6)\n",
    "    weights = weights / weights.mean()\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "    print(\"Class weights:\", weights)\n",
    "\n",
    "base_loss = nn.CrossEntropyLoss(\n",
    "    weight=class_weights,\n",
    "    label_smoothing=config[\"label_smoothing\"]\n",
    ")\n",
    "\n",
    "# 2. Teacher Setup & Training\n",
    "teacher_model = None\n",
    "if config[\"use_distill\"]:\n",
    "    teacher_model = timm.create_model(\n",
    "        config[\"teacher_backbone\"],\n",
    "        pretrained=True,\n",
    "        num_classes=config[\"num_classes\"]\n",
    "    ).to(device)\n",
    "    print(f\"âœ… Teacher initialized: {config['teacher_backbone']}\")\n",
    "\n",
    "    if config[\"train_teacher\"]:\n",
    "        print(\"\\nðŸŽ“ Starting Teacher Training...\")\n",
    "\n",
    "        for p in teacher_model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        t_opt = optim.AdamW(teacher_model.parameters(), lr=config[\"lr\"] * 0.5)\n",
    "        t_sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            t_opt,\n",
    "            max_lr=config[\"lr\"],\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            epochs=config[\"teacher_epochs\"]\n",
    "        )\n",
    "        t_trainer = Trainer(teacher_model, base_loss, t_opt, t_sched, device, config)\n",
    "\n",
    "        best_t_loss = float(\"inf\")\n",
    "        for ep in range(config[\"teacher_epochs\"]):\n",
    "            tl = t_trainer.train_epoch(train_loader, ep, config[\"teacher_epochs\"])\n",
    "\n",
    "            teacher_model.eval()\n",
    "            vl, tot = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs, labels = imgs.to(device), labels.to(device)\n",
    "                    vl += base_loss(teacher_model(imgs), labels).item() * imgs.size(0)\n",
    "                    tot += imgs.size(0)\n",
    "            vl /= max(1, tot)\n",
    "            print(f\"Teacher Epoch {ep+1}/{config['teacher_epochs']} - \"\n",
    "                  f\"Train: {tl:.4f} - Val: {vl:.4f}\")\n",
    "\n",
    "            if vl < best_t_loss:\n",
    "                best_t_loss = vl\n",
    "                torch.save(teacher_model.state_dict(), \"best_teacher.pth\")\n",
    "\n",
    "        if os.path.exists(\"best_teacher.pth\"):\n",
    "            teacher_model.load_state_dict(\n",
    "                torch.load(\"best_teacher.pth\", map_location=device)\n",
    "            )\n",
    "        print(\"ðŸŽ“ Teacher Training Complete.\\n\")\n",
    "\n",
    "# 3. Initialize Distillation Loss\n",
    "if config[\"use_distill\"]:\n",
    "    criterion = DistillationLoss(\n",
    "        base_loss,\n",
    "        teacher_model=teacher_model,\n",
    "        alpha_start=config[\"distill_alpha_start\"],\n",
    "        alpha_end=config[\"distill_alpha_end\"]\n",
    "    )\n",
    "else:\n",
    "    criterion = base_loss\n",
    "\n",
    "# 4. Student Setup (with persistence images)\n",
    "model = EfficientNetWithCBAM_PI(\n",
    "    backbone_name=config[\"backbone\"],\n",
    "    num_classes=config[\"num_classes\"],\n",
    "    use_cbam=config[\"use_cbam\"],\n",
    "    pretrained=True,\n",
    "    use_tda=config[\"use_tda\"],\n",
    "    tda_img_size=config[\"tda_img_size\"],\n",
    "    tda_mlp_dims=config[\"tda_mlp_dims\"]\n",
    ").to(device)\n",
    "print(f\"âœ… Student initialized: {config['backbone']} (TDA PI Fusion: {config['use_tda']})\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=config[\"lr\"] * 5,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=config[\"epochs\"]\n",
    ")\n",
    "trainer = Trainer(model, criterion, optimizer, scheduler, device, config)\n",
    "\n",
    "# 5. Student Training Loop (using val set for early stopping)\n",
    "train_losses = []\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = config[\"early_stop_patience\"]\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    train_loss = trainer.train_epoch(train_loader, epoch, config[\"epochs\"])\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation (for early stopping & model selection)\n",
    "    model.eval()\n",
    "    val_loss, total = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            if isinstance(criterion, DistillationLoss):\n",
    "                criterion.set_epoch(epoch, config[\"epochs\"])\n",
    "                loss = criterion(outputs, imgs, labels)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            total += imgs.size(0)\n",
    "\n",
    "    val_loss /= max(1, total)\n",
    "    print(f\"Epoch {epoch+1}/{config['epochs']} - \"\n",
    "          f\"Train: {train_loss:.4f} - Val: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"âœ… Model saved.\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"âš  No improvement ({counter}/{patience})\")\n",
    "        if counter >= patience:\n",
    "            print(\"ðŸ›‘ Early stopping.\")\n",
    "            break\n",
    "\n",
    "# 6. Evaluation on TEST SET (unbiased final evaluation)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Load best model for final evaluation\n",
    "if os.path.exists(\"best_model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ FINAL TEST SET EVALUATION (UNBIASED)\")\n",
    "print(\"=\"*60)\n",
    "test_preds, test_trues = trainer.evaluate(test_loader)\n",
    "print(classification_report(test_trues, test_preds, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(test_trues, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title(\"Test Set Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 7. Grad-CAM Visualization (using test set samples)\n",
    "# -------------------------\n",
    "def denormalize_image(img_tensor):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    img = img * std + mean\n",
    "    img = np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def get_gradcam_target_layer(model):\n",
    "    if getattr(model, \"cbam\", None) is not None:\n",
    "        return model.cbam\n",
    "    return model.feature_extractor\n",
    "\n",
    "def generate_gradcam(model, img_tensor, class_idx, target_layer):\n",
    "    model.eval()\n",
    "    activations = {}\n",
    "    gradients = {}\n",
    "\n",
    "    def forward_hook(module, inp, out):\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            activations[\"value\"] = out[-1].detach()\n",
    "        else:\n",
    "            activations[\"value\"] = out.detach()\n",
    "\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        g = grad_out[0]\n",
    "        if isinstance(g, (list, tuple)):\n",
    "            gradients[\"value\"] = g[-1].detach()\n",
    "        else:\n",
    "            gradients[\"value\"] = g.detach()\n",
    "\n",
    "    fwd_handle = target_layer.register_forward_hook(forward_hook)\n",
    "    bwd_handle = target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "    outputs = model(img_tensor)\n",
    "\n",
    "    model.zero_grad()\n",
    "    score = outputs[0, class_idx]\n",
    "    score.backward()\n",
    "\n",
    "    fwd_handle.remove()\n",
    "    bwd_handle.remove()\n",
    "\n",
    "    A = activations[\"value\"]\n",
    "    G = gradients[\"value\"]\n",
    "    weights = torch.mean(G, dim=(2, 3), keepdim=True)\n",
    "    cam = torch.sum(weights * A, dim=1).squeeze(0)\n",
    "    cam = torch.relu(cam)\n",
    "    cam = cam.cpu().numpy()\n",
    "    cam -= cam.min()\n",
    "    cam /= (cam.max() + 1e-8)\n",
    "    return cam\n",
    "\n",
    "# Generate Grad-CAMs from test set\n",
    "os.makedirs(config[\"gradcam_out_dir\"], exist_ok=True)\n",
    "model.eval()\n",
    "print(\"\\nðŸ”¥ Generating Grad-CAMs from test set...\")\n",
    "\n",
    "target_layer = get_gradcam_target_layer(model)\n",
    "cls_seen = {i: False for i in range(config[\"num_classes\"])}\n",
    "\n",
    "dataset_ref = test_ds.dataset if isinstance(test_ds, Subset) else test_ds\n",
    "indices = test_ds.indices if isinstance(test_ds, Subset) else range(len(test_ds))\n",
    "\n",
    "for ds_idx in indices:\n",
    "    if all(cls_seen.values()):\n",
    "        break\n",
    "        \n",
    "    img, label = dataset_ref[ds_idx]\n",
    "\n",
    "    if cls_seen[label]:\n",
    "        continue\n",
    "\n",
    "    cls_seen[label] = True\n",
    "\n",
    "    cam = generate_gradcam(model, img, label, target_layer)\n",
    "    cam = cv2.resize(cam, (config[\"image_size\"], config[\"image_size\"]))\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    orig = denormalize_image(img)\n",
    "    overlay = cv2.addWeighted(orig, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    save_path = os.path.join(\n",
    "        config[\"gradcam_out_dir\"],\n",
    "        f\"gradcam_test_class_{class_names[label]}.jpg\"\n",
    "    )\n",
    "    cv2.imwrite(save_path, overlay)\n",
    "    print(f\"âœ” Saved Grad-CAM for class {class_names[label]} â†’ {save_path}\")\n",
    "\n",
    "print(\"ðŸŽ‰ Grad-CAM generation complete.\")\n",
    "print(\"âœ… Pipeline complete with proper train/val/test split!\")\n",
    "\n",
    "# extension of model_9_v3\n",
    "# final code\n",
    "# test set evaluation is there in this code.\n",
    "# no stratified sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
